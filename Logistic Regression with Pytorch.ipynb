{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                              train=True,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num = 101\n",
    "\n",
    "img_example = train_dataset[img_num][0].numpy().reshape(28,28)\n",
    "img_example.shape\n",
    "plt.imshow(img_example, cmap='gray')\n",
    "print('Label {}'.format(train_dataset[img_num][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make datasets iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 3000.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "iterations = epochs * len(train_dataset)/batch_size\n",
    "print('Iterations {}'.format(iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for dataset iterability\n",
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for dataset iterability\n",
    "import collections\n",
    "isinstance(test_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.Linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.Linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "model = LogisticRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (Linear): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0107, -0.0262, -0.0162,  ..., -0.0071, -0.0035,  0.0063],\n",
       "         [-0.0158,  0.0321,  0.0351,  ..., -0.0011, -0.0285, -0.0332],\n",
       "         [-0.0106,  0.0056, -0.0063,  ..., -0.0171,  0.0299, -0.0098],\n",
       "         ...,\n",
       "         [ 0.0351,  0.0276,  0.0343,  ..., -0.0188, -0.0357, -0.0324],\n",
       "         [-0.0263,  0.0353,  0.0135,  ..., -0.0339,  0.0210, -0.0203],\n",
       "         [-0.0026,  0.0193, -0.0252,  ...,  0.0284, -0.0030, -0.0139]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-0.0250,  0.0305, -0.0147, -0.0256,  0.0273,  0.0008,  0.0079, -0.0185,\n",
       "         -0.0127, -0.0213], requires_grad=True)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficents : torch.Size([10, 784])\n",
      "Bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print('Coefficents : {}'.format(list(model.parameters())[0].shape))\n",
    "print('Bias : {}'.format(list(model.parameters())[1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iter 500, Loss 0.8704499006271362, Accuracy 84.85\n",
      "Epoch 1, Iter 1000, Loss 0.6596279740333557, Accuracy 87.09\n",
      "Epoch 2, Iter 1500, Loss 0.5788799524307251, Accuracy 87.85\n",
      "Epoch 3, Iter 2000, Loss 0.45839253067970276, Accuracy 88.47\n",
      "Epoch 4, Iter 2500, Loss 0.35587742924690247, Accuracy 88.95\n",
      "Epoch 4, Iter 3000, Loss 0.5180630087852478, Accuracy 89.22\n",
      "Training time 73.30112791061401\n"
     ]
    }
   ],
   "source": [
    "#CPU implementation\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "model = LogisticRegression(input_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "accuracy = -999\n",
    "itern = 0\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_val = loss.data.numpy().reshape(1)[0]\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        itern += 1\n",
    "        if itern%500 ==0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for test_images, test_labels in test_loader:\n",
    "                test_images = Variable(test_images.view(-1, 28*28))\n",
    "                test_preds = model(test_images)\n",
    "                _, predicted = torch.max(test_preds.data, 1)\n",
    "                total +=  test_labels.size(0)\n",
    "                correct += (predicted == test_labels).sum()\n",
    "            correct = correct.numpy().reshape(1)[0]\n",
    "            accuracy = 100 * correct/total    \n",
    "            print('Epoch {}, Iter {}, Loss {}, Accuracy {}'.format(epoch, itern,loss_val, accuracy))\n",
    "print('Training time {}'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iter 500, Loss 0.8775678277015686, Accuracy 84.78\n",
      "Epoch 1, Iter 1000, Loss 0.7548774480819702, Accuracy 86.96\n",
      "Epoch 2, Iter 1500, Loss 0.4737601578235626, Accuracy 88.03\n",
      "Epoch 3, Iter 2000, Loss 0.4712175130844116, Accuracy 88.56\n",
      "Epoch 4, Iter 2500, Loss 0.4331512749195099, Accuracy 89.04\n",
      "Epoch 4, Iter 3000, Loss 0.40139007568359375, Accuracy 89.28\n",
      "Training time 41.84153485298157\n"
     ]
    }
   ],
   "source": [
    "#GPU implementation\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "model = LogisticRegression(input_dim, output_dim)\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "accuracy = -999\n",
    "itern = 0\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.view(-1,28*28).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_val = loss.data.cpu().numpy().reshape(1)[0]\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        itern += 1\n",
    "        if itern%500 ==0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for test_images, test_labels in test_loader:\n",
    "                test_images = Variable(test_images.view(-1, 28*28).cuda())\n",
    "                test_preds = model(test_images)\n",
    "                _, predicted = torch.max(test_preds.data, 1)  \n",
    "                predicted = predicted.cpu()\n",
    "                total +=  test_labels.size(0)\n",
    "                correct += (predicted == test_labels).sum()\n",
    "            correct = correct.numpy().reshape(1)[0]\n",
    "            accuracy = 100 * correct/total    \n",
    "            print('Epoch {}, Iter {}, Loss {}, Accuracy {}'.format(epoch, itern,loss_val, accuracy))\n",
    "print('Training time {}'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
